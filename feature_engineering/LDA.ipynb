{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data processing and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random\n",
    "\n",
    "# Analytics and modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Graphing and visualizing\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "from pylab import savefig\n",
    "\n",
    "from scipy import sparse, io\n",
    "import logging, gensim, bz2\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "import Pyro4\n",
    "import os\n",
    "# Setting graphing preferences\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "\n",
    "# Printing\n",
    "import locale\n",
    "\n",
    "# Show plots locally\n",
    "locale.setlocale( locale.LC_ALL, '' )\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create temp folder to store corpus and dictionary\n",
    "import tempfile\n",
    "TEMP_FOLDER = tempfile.gettempdir()\n",
    "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the lyrics data\n",
    "path = r'C:\\Users\\abhij\\Desktop\\UVa Coursework\\SYS 6018\\lyric_analysis'\n",
    "file = \"/Song_sample_file.csv\"\n",
    "\n",
    "df = pd.read_csv(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46574, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop index from merge and check shape\n",
    "df.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to separate eTraina dn test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"title\", \"artist\", \"full_lyrics\"]], \n",
    "                                                    df.chart, random_state=42)\n",
    "train = pd.concat([X_train,y_train], axis = 1)\n",
    "test = pd.concat([X_test,y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Separate lyrical content to feature engineer\n",
    "train_lyrics = train[\"full_lyrics\"]\n",
    "test_lyrics = test[\"full_lyrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "train_lyrics = [[word for word in lyric.lower().split() if word not in stoplist]\n",
    "          for lyric in train_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for lyric in train_lyrics:\n",
    "     for token in lyric:\n",
    "        frequency[token] += 1\n",
    "\n",
    "train_lyrics = [[token for token in lyric if frequency[token] > 1]\n",
    "          for lyric in train_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Build the dictionary\n",
    "train_dict = corpora.Dictionary(train_lyrics)\n",
    "train_dict.save(os.path.join(TEMP_FOLDER, 'train.dict'))  # store the dictionary, for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build corpus\n",
    "train_corpus = [train_dict.doc2bow(text) for text in train_lyrics]\n",
    "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER,'train.mm'), train_corpus)  # store to disk, for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run LDA model with 20 topics\n",
    "lda_train = gensim.models.LdaMulticore(corpus=train_corpus, id2word=train_dict, num_topics=20, chunksize=20, passes=1, workers = 4, minimum_probability = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain LDA weights for all songs based on trained model and convert to data frame\n",
    "lda_weights = [dict(lda_train[train_dict.doc2bow(x.split())]) for x in df.full_lyrics]\n",
    "\n",
    "lda_weights = pd.DataFrame(lda_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save weights for modelling\n",
    "lda_weights.to_csv(\"lda_weights.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
