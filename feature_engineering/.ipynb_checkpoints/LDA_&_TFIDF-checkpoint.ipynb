{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data processing and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random\n",
    "\n",
    "# Analytics and modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Graphing and visualizing\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "from pylab import savefig\n",
    "\n",
    "import logging, gensim, bz2\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "import Pyro4\n",
    "import os\n",
    "# Setting graphing preferences\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "\n",
    "# Printing\n",
    "import locale\n",
    "\n",
    "# Show plots locally\n",
    "locale.setlocale( locale.LC_ALL, '' )\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create temp folder to store corpus and dictionary\n",
    "import tempfile\n",
    "TEMP_FOLDER = tempfile.gettempdir()\n",
    "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the lyrics data\n",
    "path = r'C:\\Users\\abhij\\Desktop\\UVa Coursework\\SYS 6018\\lyric_analysis'\n",
    "file = \"/Song_sample_file.csv\"\n",
    "\n",
    "df = pd.read_csv(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46574, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop index from merge and check shape\n",
    "df.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to separate eTraina dn test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"title\", \"artist\", \"full_lyrics\"]], \n",
    "                                                    df.chart, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lyrics = train[\"full_lyrics\"]\n",
    "test_lyrics = test[\"full_lyrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "train_lyrics = [[word for word in lyric.lower().split() if word not in stoplist]\n",
    "          for lyric in train_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for lyric in train_lyrics:\n",
    "     for token in lyric:\n",
    "        frequency[token] += 1\n",
    "\n",
    "train_lyrics = [[token for token in lyric if frequency[token] > 1]\n",
    "          for lyric in train_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build the dictionary\n",
    "train_dict = corpora.Dictionary(train_lyrics)\n",
    "train_dict.save(os.path.join(TEMP_FOLDER, 'train.dict'))  # store the dictionary, for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_corpus = [train_dict.doc2bow(text) for text in train_lyrics]\n",
    "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER,'train.mm'), train_corpus)  # store to disk, for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run LDA model with 20 topics\n",
    "lda_train = gensim.models.LdaMulticore(corpus=train_corpus, id2word=train_dict, num_topics=20, chunksize=20, passes=1, workers = 4, minimum_probability = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights = [dict(lda_train[train_dict.doc2bow(x.split())]) for x in df.full_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights = pd.DataFrame(lda_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_weights.to_csv(\"lda_weights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_list = df.full_lyrics.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 20)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(lyric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse, io\n",
    "io.mmwrite(\"tfidf.mtx\",tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_names_tfidf.txt\", \"w\") as output:\n",
    "    output.write(str(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('df', 64812962),\n",
       " ('DecisionTreeClassifier', 1056),\n",
       " ('PolynomialFeatures', 1056),\n",
       " ('StandardScaler', 1056),\n",
       " ('accuracy_score', 136),\n",
       " ('classification_report', 136),\n",
       " ('confusion_matrix', 136),\n",
       " ('cross_val_predict', 136),\n",
       " ('cross_val_score', 136),\n",
       " ('roc_auc_score', 136),\n",
       " ('roc_curve', 136),\n",
       " ('savefig', 136),\n",
       " ('train_test_split', 136),\n",
       " ('path', 110),\n",
       " ('cm', 80),\n",
       " ('colors', 80),\n",
       " ('corpora', 80),\n",
       " ('linear_model', 80),\n",
       " ('models', 80),\n",
       " ('mpl', 80),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('plt', 80),\n",
       " ('similarities', 80),\n",
       " ('sns', 80),\n",
       " ('sp', 80),\n",
       " ('file', 70)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') \n",
    "        and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
